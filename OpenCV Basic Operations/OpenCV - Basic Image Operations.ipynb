{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started with OpenCV and Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading and diplaying images\n",
    "img=cv2.imread(\"butterfly.jpg\")                #reading using imread\n",
    "cv2.namedWindow(\"Butterfly\",cv2.WINDOW_NORMAL) #namedwindow with normalwindow placeholder\n",
    "cv2.imshow(\"Butterfly\",img)                    #diplaying the image in the same named window\n",
    "cv2.waitKey(0)                                 #window will be opened until the user presses any key\n",
    "cv2.destroyAllWindows()                        #destroying all the opened windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access and Understand Pixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixels in an image :\n",
      " [[[ 57  91  54]\n",
      "  [ 52  86  49]\n",
      "  [ 44  78  41]\n",
      "  ...\n",
      "  [165 149 136]\n",
      "  [172 150 144]\n",
      "  [178 153 151]]\n",
      "\n",
      " [[ 55  89  52]\n",
      "  [ 49  83  46]\n",
      "  [ 41  75  38]\n",
      "  ...\n",
      "  [163 150 142]\n",
      "  [171 151 150]\n",
      "  [176 153 157]]\n",
      "\n",
      " [[ 53  87  50]\n",
      "  [ 47  81  44]\n",
      "  [ 37  74  36]\n",
      "  ...\n",
      "  [163 152 155]\n",
      "  [169 153 164]\n",
      "  [173 156 169]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 47 124  62]\n",
      "  [ 51 124  62]\n",
      "  [ 59 123  63]\n",
      "  ...\n",
      "  [111 229 216]\n",
      "  [110 228 210]\n",
      "  [ 88 207 186]]\n",
      "\n",
      " [[ 45 122  60]\n",
      "  [ 49 122  60]\n",
      "  [ 57 121  62]\n",
      "  ...\n",
      "  [108 226 213]\n",
      "  [110 229 214]\n",
      "  [ 88 210 194]]\n",
      "\n",
      " [[ 45 124  61]\n",
      "  [ 51 124  62]\n",
      "  [ 60 124  65]\n",
      "  ...\n",
      "  [103 221 208]\n",
      "  [104 224 213]\n",
      "  [ 92 214 203]]]\n"
     ]
    }
   ],
   "source": [
    "#to see the array of pixels in the image\n",
    "print(\"Pixels in an image :\\n\",img)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of Image: <class 'numpy.ndarray'>\n",
      "length of an image(rows): 217\n",
      "length of an image(columns): 300\n",
      "length of an image(channels): 3\n",
      "size of an image: 195300\n",
      "shape of an image: (217, 300, 3)\n",
      "dtype: uint8\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of Image:\",type(img))                      #type of image-numpy\n",
    "print(\"length of an image(rows):\",len(img))            #number of rows\n",
    "print(\"length of an image(columns):\",len(img[0]))      #number of columns\n",
    "print(\"length of an image(channels):\",len(img[0][0]))  #number of channels\n",
    "print(\"size of an image:\",img.size)                    #number of elements in an image array\n",
    "print(\"shape of an image:\", img.shape)                 #shape of a image\n",
    "print(\"dtype:\",img.dtype)                              #data type of the ekement in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To access the single channel of an image:\n",
      " [[ 57  52  44 ... 165 172 178]\n",
      " [ 55  49  41 ... 163 171 176]\n",
      " [ 53  47  37 ... 163 169 173]\n",
      " ...\n",
      " [ 47  51  59 ... 111 110  88]\n",
      " [ 45  49  57 ... 108 110  88]\n",
      " [ 45  51  60 ... 103 104  92]]\n",
      "\n",
      "\n",
      "To access all the channels in the single pixel of an image:\n",
      " [57 91 54]\n"
     ]
    }
   ],
   "source": [
    "print(\"To access the single channel of an image:\\n\",img[:,:,0])\n",
    "print(\"\\n\")\n",
    "print(\"To access all the channels in the single pixel of an image:\\n\",img[0,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatypes and structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1 1 1]\n",
      "[65535 65535 65535]\n",
      "[255   0   0]\n"
     ]
    }
   ],
   "source": [
    "#black\n",
    "black=np.zeros([150,200,1],'uint8')\n",
    "cv2.imshow(\"Black\",black)\n",
    "print(black[0,0,:])\n",
    "\n",
    "#black\n",
    "ones=np.ones([150,200,3],'uint8')\n",
    "cv2.imshow(\"Ones\",ones)\n",
    "print(ones[0,0,:])\n",
    "\n",
    "#white\n",
    "white=np.ones([150,200,3],'uint16')\n",
    "white*=(2**16-1)\n",
    "cv2.imshow(\"White\",white)\n",
    "print(white[0,0,:])\n",
    "\n",
    "#blue\n",
    "blue = ones.copy()\n",
    "blue[:,:]=(255,0,0)\n",
    "cv2.imshow(\"Blue\",blue)\n",
    "print(blue[0,0,:])\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image types and color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read an image and display\n",
    "img=cv2.imread(\"butterfly.jpg\")\n",
    "cv2.namedWindow(\"Butterfly\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Butterfly\",img)\n",
    "cv2.moveWindow(\"Butterfly\",0,0)\n",
    "#store height,width and channel in the variable respectively\n",
    "height,width,channel= img.shape\n",
    "#split the channels in the image as the separate components\n",
    "b,g,r=cv2.split(img)\n",
    "\n",
    "#create an empty array of mentioned size and show the different channel separately\n",
    "rgb_split = np.empty([height,width*3,channel],'uint8')\n",
    "rgb_split[:,0:width]=cv2.merge([b,b,b])\n",
    "rgb_split[:,width:width*2]=cv2.merge([g,g,g])\n",
    "rgb_split[:,width*2:width*3]=cv2.merge([r,r,r])\n",
    "cv2.imshow(\"Channel\",rgb_split)\n",
    "#movewindow wil help to show all the images in an arranged way based on x and y value\n",
    "cv2.moveWindow(\"Channel\",0,height+20)\n",
    "#hue (all color),saturation(how saturated the color is) and value(brightness or luminous of the color)\n",
    "hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)          #convertingbgr color to hsv\n",
    "h,s,v=cv2.split(hsv)                             #split and concatenating horizantally\n",
    "hsv_split=np.concatenate((h,s,v),axis=1)\n",
    "cv2.imshow(\"Split hsv\",hsv_split)\n",
    "cv2.moveWindow(\"Split hsv\",0,height+height+40)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel Manipulation and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading and displaying the image\n",
    "img=cv2.imread(\"butterfly.jpg\")\n",
    "cv2.namedWindow(\"Butterfly\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Butterfly\",img)\n",
    "cv2.moveWindow(\"Butterfly\",0,0)\n",
    "#converting to gray image\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "cv2.imshow(\"Gray\",gray)\n",
    "cv2.moveWindow(\"Gray\",width+20,0)\n",
    "#split the each channel using arraying slicing(this method is more efficient than cv2.split(img))\n",
    "r=img[:,:,0]\n",
    "g=img[:,:,1]\n",
    "b=img[:,:,2]\n",
    "#merging all together along with transparency(alpha channel) together at the end (g-to make non green parts of the image transparent)\n",
    "rgba=cv2.merge([r,g,b,g])\n",
    "cv2.imwrite('rgba.png',rgba) #should save it as png not jpg as jpg doesnt support transparency\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blur, dilation and erosion\n",
    "[Click here to learn about erosion and dilation](https://www.youtube.com/watch?v=2LAooUu1IjQ)\n",
    "\n",
    "[click here to learn the difference](https://www.geeksforgeeks.org/difference-between-dilation-and-erosion/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading and displaying the image\n",
    "image=cv2.imread(\"noise.jpg\")\n",
    "cv2.namedWindow(\"Original\",cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"Original\",image)\n",
    "\n",
    "#gaussian blur\n",
    "blur=cv2.GaussianBlur(image,(5,5),0)\n",
    "cv2.imshow(\"Blur\",blur)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#dilation-1 if any of the structuring element is 1\n",
    "#erosion - 1 only if all the structuring elements are 1\n",
    "#erosion and dilation\n",
    "kernel=np.ones((5,5),'uint8')\n",
    "erode=cv2.erode(gray,None,iterations=2)\n",
    "dilate=cv2.dilate(gray,None,iterations=1)\n",
    "\n",
    "cv2.imshow(\"Dilation\",dilate)\n",
    "cv2.imshow(\"Erosion\",erode)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale and Rotate Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"butterfly.jpg\")\n",
    "cv2.namedWindow(\"Butterfly\",cv2.WINDOW_NORMAL)\n",
    "#scaling\n",
    "img_half=cv2.resize(img,(100,0),fx=0.5,fy=0.5)\n",
    "img_stretch=cv2.resize(img,(400,400))\n",
    "img_stretch_near=cv2.resize(img,(400,400),interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "cv2.imshow(\"Butterfly\",img)\n",
    "cv2.imshow(\"Butterfly_half_sized\",img_half)\n",
    "cv2.imshow(\"Butterfly_stretch\",img_stretch)\n",
    "cv2.imshow(\"Butterfly_stretch_near\",img_stretch_near)\n",
    "\n",
    "cv2.moveWindow(\"Butterfly\",0,0)\n",
    "cv2.moveWindow(\"Butterfly_half_sized\",300,0)\n",
    "cv2.moveWindow(\"Butterfly_stretch\",450,0)\n",
    "cv2.moveWindow(\"Butterfly_stretch_near\",800,0)\n",
    "#rotating\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]\n",
    "(cX,cY) = (width//2,height//2)\n",
    "\n",
    "M=cv2.getRotationMatrix2D((0,0),-30,1)\n",
    "rotated=cv2.warpAffine(img,M,(width,height))\n",
    "cv2.imshow(\"rotated\",rotated)\n",
    "cv2.moveWindow(\"rotated\",0,height)\n",
    "\n",
    "M1=cv2.getRotationMatrix2D((cX,cY),-30,1)\n",
    "rotated_center=cv2.warpAffine(img,M1,(width,height))\n",
    "cv2.imshow(\"rotated_center\",rotated_center)\n",
    "cv2.moveWindow(\"rotated_center\",300,height)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple and Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw =cv2.imread('sudoku.jpg',0)\n",
    "height,width = bw.shape[0:2]\n",
    "cv2.imshow(\"Original BW\",bw)\n",
    "\n",
    "binary=np.zeros([height,width,1],'uint8')\n",
    "thresh=75\n",
    "for row in range(0,height):\n",
    "    for col in range(0,width):\n",
    "        if bw[row][col]>thresh:\n",
    "            binary[row][col]=255\n",
    "cv2.imshow(\"Slow Binary\",binary)\n",
    "            \n",
    "ret,thresh=cv2.threshold(bw,thresh,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Simple Threshold\",thresh)\n",
    "\n",
    "thresh_adapt=cv2.adaptiveThreshold(bw,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,115,1)\n",
    "cv2.imshow(\"Adaptive Threshold\",thresh_adapt)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skin Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_image=cv2.imread(\"skin.jpeg\",1)\n",
    "hsv=cv2.cvtColor(skin_image,cv2.COLOR_BGR2HSV)\n",
    "h=hsv[:,:,0]\n",
    "s=hsv[:,:,1]\n",
    "v=hsv[:,:,2]\n",
    "hsv_split=np.concatenate((h,s,v),axis=1)\n",
    "cv2.imshow(\"split HSV\",hsv_split)\n",
    "\n",
    "ret,min_sat=cv2.threshold(s,40,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Sat Filter\",min_sat)\n",
    "\n",
    "ret,max_hue=cv2.threshold(h,15,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Hue Filter\",max_hue)\n",
    "\n",
    "final=cv2.bitwise_and(min_sat,max_hue)\n",
    "cv2.imshow(\"final\",final)\n",
    "cv2.imshow(\"Original\",skin_image)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
